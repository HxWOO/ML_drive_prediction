
# Porto Seguro 안전 운전자 예측

이 프로젝트는 [Porto Seguro의 안전 운전자 예측](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) Kaggle 대회를 위한 분석 및 모델 개발 과정을 담고 있습니다. 목표는 운전자가 내년에 자동차 보험 청구를 시작할지 여부를 예측하는 것입니다.

## 💻 프로젝트 워크플로우

프로젝트는 다음과 같은 단계로 진행되었습니다.

1.  **탐색적 데이터 분석 (EDA)**
2.  **베이스라인 모델 개발**
3.  **모델 성능 개선 과정**
4.  **결과 및 개선점**

---

### 1. 탐색적 데이터 분석 (EDA)

본격적인 모델링에 앞서 데이터의 특징을 파악했습니다.

-   **데이터 구조**: 59개의 피처(id, target 제외 57개)와 595,212개의 행으로 구성되어 있습니다.
-   **피처 유형**: 변수 이름에 포함된 `ind`, `reg`, `car`, `calc` 접미사를 통해 개인, 지역, 차량, 계산된 피처로 그룹화하고, `bin`(이진), `cat`(범주형) 접미사를 통해 데이터 유형을 식별했습니다.
-   **결측치**: 결측값은 `-1`로 표기되어 있으며, 여러 피처에 걸쳐 존재함을 확인했습니다.
-   **타겟 변수 불균형**: 보험을 청구한 경우(Target=1)가 약 3.64%에 불과한 심각한 데이터 불균형 문제를 확인했습니다. 따라서 정확도(Accuracy)가 아닌 **Gini 계수**를 핵심 평가지표로 사용해야 함을 파악했습니다.
-   **시각화 분석**: 상관관계 히트맵 분석 결과, `ps_calc` 그룹의 피처들은 서로 독립적이지만 예측 기여도는 낮을 것으로 예상했습니다.

### 2. 베이스라인 모델 개발

-   **모델 선택**: 성능이 우수하고 학습 속도가 빠른 `LightGBM`을 베이스라인 모델로 선정했습니다.
-   **기본 전처리**:
    -   EDA에서 유용하지 않을 것으로 판단된 `ps_calc_*` 피처 그룹 전체를 제거했습니다.
    -   결측치가 과도하게 많은 `ps_car_03_cat`, `ps_car_05_cat` 피처를 제거했습니다.
    -   -1 값을 `NaN`으로 변환하고, 범주형 피처의 `NaN`은 최빈값으로 단순 대체했습니다.
-   **검증 방식**: `StratifiedKFold` (5-Fold) 교차 검증을 사용하여 OOF(Out-of-Fold) 예측값을 생성하고 Gini 계수를 측정했습니다.
-   **초기 성능**: **약 0.278**의 OOF Gini 점수를 기록했습니다.

### 3. 모델 성능 개선 과정

베이스라인 모델의 성능을 향상시키기 위해 다음과 같은 기법들을 순차적으로 적용했습니다.

1.  **피처 엔지니어링 (One-Hot Encoding)**
    -   범주형 피처들을 `pd.get_dummies`를 사용해 원-핫 인코딩하여 모델이 범주를 순서형으로 오해하지 않도록 처리했습니다.
    -   **Gini 점수가 0.284로 상승**하며 성능 개선에 효과적임을 확인했습니다.

2.  **하이퍼파라미터 튜닝 (Optuna)**
    -   베이지안 최적화 기반의 `Optuna` 라이브러리를 사용하여 `LightGBM`과 `XGBoost` 모델의 최적 하이퍼파라미터를 탐색했습니다.
    -   이를 통해 각 모델의 성능을 개별적으로 최대화했습니다. (LightGBM: ~0.286, XGBoost: ~0.286)

3.  **앙상블 (Ensemble) 및 스태킹 (Stacking)**
    -   최적화된 `LightGBM`과 `XGBoost` 모델의 예측 결과를 결합하여 성능을 더욱 끌어올리고자 했습니다.
    -   **가중치 평균(Blending)**: OOF 예측값을 기반으로 최적의 가중치(XGBoost: 0.64, LightGBM: 0.36)를 찾아 적용했을 때 **Gini 점수가 0.2864**로 소폭 상승했습니다.
    -   **스태킹(Stacking)**: 두 모델의 OOF 예측값을 피처로 사용하여 `LogisticRegression` 메타 모델을 학습시켰습니다. (베이스 모델이 2개뿐이라 가중치 평균과 거의 동일한 성능을 보였습니다.)

4.  **피처 엔지니어링 (피처 추가)**
    -   결측값 개수, 이진 피처 합계, 상호작용 피처(`ps_car_13 * ps_reg_03` 등)를 추가하여 모델에 더 많은 정보를 제공하고자 했습니다.
    -   **결과적으로 성능이 오히려 하락**하여, 해당 피처들이 노이즈로 작용했음을 확인했습니다.

### 4. 결과 및 개선점

-   **최종 모델**: 하이퍼파라미터 튜닝이 완료된 `XGBoost` 단일 모델과, 이를 `LightGBM`과 최적 가중치로 앙상블한 모델이 가장 좋은 성능(**OOF Gini: ~0.286**)을 보였습니다.
-   **주요 교훈**: 무분별한 피처 추가는 오히려 성능을 저해할 수 있으며, 피처의 유용성에 대한 깊은 고민이 필요함을 확인했습니다.
-   **개선 방향**:
    -   **정교한 피처 엔지니어링**: 도메인 지식을 활용하거나, 다른 상호작용 및 다항 피처를 생성하여 모델에 유의미한 정보를 추가해야 합니다.
    -   **다양한 모델 추가**: CatBoost, Neural Network 등 더 다양한 모델을 앙상블에 추가하여 모델의 다양성을 확보하고 성능을 높일 수 있습니다.
    -   **결측치 처리**: 단순히 최빈값으로 대체하는 대신, 결측값 자체를 하나의 정보로 활용하거나 다른 모델(e.g., KNN)을 이용해 예측하여 채우는 방식을 시도해볼 수 있습니다.

---

## 🚀 시작하기

### 사전 요구 사항

-   Python 3.x
-   pandas, numpy, seaborn, matplotlib, scikit-learn, lightgbm, xgboost, optuna

```bash
pip install pandas numpy seaborn matplotlib scikit-learn lightgbm xgboost optuna
```

### 사용법

1.  이 저장소를 복제(Clone)합니다.
2.  `porto-seguro-safe-driver-prediction-data/` 디렉토리에 Kaggle 대회 데이터를 위치시킵니다.
3.  `porto-seguro-safe-driver-prediction.ipynb` Jupyter Notebook을 실행하여 전체 분석 및 모델링 과정을 확인할 수 있습니다.
